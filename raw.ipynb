{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-02T20:23:52.702898Z",
     "start_time": "2017-10-02T20:23:37.242856Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-02T20:23:52.711699Z",
     "start_time": "2017-10-02T20:23:52.704827Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import scipy.special"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-02T20:23:52.933145Z",
     "start_time": "2017-10-02T20:23:52.714056Z"
    }
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork():\n",
    "    \n",
    "    # initialize NeuralNetwork\n",
    "    def __init__(self, n_inodes, n_hnodes, n_onodes, lrate):\n",
    "        # set the number of nodes in each layer\n",
    "        self.n_inodes = n_inodes\n",
    "        self.n_hnodes = n_hnodes\n",
    "        self.n_onodes = n_onodes\n",
    "        \n",
    "        # learning rate\n",
    "        self.lr = lrate\n",
    "        \n",
    "        ''' weight initialization, by np.rand \n",
    "            np.rand(rows, columns) - 0.5 to center from +/- 0.5\n",
    "        '''\n",
    "        self.w_i2h = (numpy.random.rand(self.n_hnodes, self.n_inodes) - 0.5)\n",
    "        self.w_h2o = (numpy.random.rand(self.n_onodes, self.n_hnodes) - 0.5)\n",
    "        \n",
    "        ''' weight initialization, by np.normal \n",
    "                (selecting from a normal distribution)\n",
    "            np.normal(center, stdev, (rows, columns))\n",
    "        '''\n",
    "        self.w_i2h = numpy.random.normal(0.0, pow(self.n_hnodes, -0.5), (self.n_hnodes, self.n_inodes))\n",
    "        self.w_h2o = numpy.random.normal(0.0, pow(self.n_onodes, -0.5), (self.n_onodes, self.n_hnodes))\n",
    "                                         \n",
    "        self.activation = lambda x: scipy.special.expit(x)\n",
    "                                         \n",
    "        pass\n",
    "    \n",
    "    # train NeuralNetwork\n",
    "    def train(self, input_list, target_list):\n",
    "        \n",
    "        inputs  = numpy.array(input_list, ndmin=2).T\n",
    "        targets = numpy.array(target_list, ndmin=2).T\n",
    "        \n",
    "        hidden_in  = numpy.dot(self.w_i2h, inputs)\n",
    "        hidden_out = self.activation(hidden_in)\n",
    "        \n",
    "        output_in  = numpy.dot(self.w_h2o, hidden_out)\n",
    "        output_out = self.activation(output_in)\n",
    "        \n",
    "        output_err = targets - output_out\n",
    "        \n",
    "        hidden_err = numpy.dot(self.w_h2o.T, output_err)\n",
    "        \n",
    "        self.w_h2o += self.lr * numpy.dot((output_err * output_out * (1 - output_out)), numpy.transpose(hidden_out))\n",
    "        \n",
    "        self.w_i2h += self.lr * numpy.dot((hidden_err * hidden_out * (1 - hidden_out)), numpy.transpose(inputs))\n",
    "\n",
    "        pass\n",
    "    \n",
    "    # query NeuralNetwork\n",
    "    def query(self, input_list):\n",
    "        inputs = numpy.array(input_list, ndmin=2).T\n",
    "                                     \n",
    "        # X_hidden = W_{input_hidden} . I\n",
    "        hidden_in  = numpy.dot(self.w_i2h, inputs)\n",
    "        # pass `hidden_in` through the activation function to calculate the output\n",
    "        hidden_out = self.activation(hidden_in)\n",
    "            \n",
    "        # X_output = W_{hidden_output} . I_{hidden_out}                                \n",
    "        output_in  = numpy.dot(self.w_h2o, hidden_out) \n",
    "         # pass `final_in` through the activation function to calculate the output\n",
    "        output_out = self.activation(output_in)\n",
    "        \n",
    "        return output_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-02T20:23:52.996126Z",
     "start_time": "2017-10-02T20:23:52.937584Z"
    }
   },
   "outputs": [],
   "source": [
    "# number of input, hidden, & output nodes\n",
    "n_inodes = 3\n",
    "n_hnodes = 3\n",
    "n_onodes = 3\n",
    "\n",
    "# learning rate\n",
    "lrate = 0.3\n",
    "\n",
    "# create an instance of NeuralNetwork\n",
    "nn = NeuralNetwork(n_inodes, n_hnodes, n_onodes, lrate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-02T20:23:53.053845Z",
     "start_time": "2017-10-02T20:23:52.999758Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.46619464],\n",
       "       [ 0.31847565],\n",
       "       [ 0.55472166]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.query([1.0, 0.5, -1.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applied to MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-02T20:23:53.104003Z",
     "start_time": "2017-10-02T20:23:53.057147Z"
    }
   },
   "outputs": [],
   "source": [
    "# number of input, hidden, & output nodes\n",
    "n_inodes = 784\n",
    "n_hnodes = 100\n",
    "n_onodes = 10\n",
    "\n",
    "# learning rate\n",
    "lrate = 0.1\n",
    "\n",
    "# create an instance of NeuralNetwork\n",
    "nn = NeuralNetwork(n_inodes, n_hnodes, n_onodes, lrate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-02T20:23:55.930305Z",
     "start_time": "2017-10-02T20:23:53.107599Z"
    }
   },
   "outputs": [],
   "source": [
    "training_data_file = open(\"MNIST_data/mnist_train.csv\", \"r\")\n",
    "training_data_list = training_data_file.readlines()\n",
    "training_data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-02T20:39:33.409284Z",
     "start_time": "2017-10-02T20:39:33.298003Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.01  0.01  0.01  0.01  0.01  0.99  0.01  0.01  0.01  0.01]\n",
      "[ 0.01  0.01  0.01  0.01  0.01  0.99  0.01  0.01  0.01  0.01]\n",
      "[ 0.01  0.01  0.01  0.01  0.01  0.99  0.01  0.01  0.01  0.01]\n",
      "[ 0.01  0.01  0.01  0.01  0.01  0.99  0.01  0.01  0.01  0.01]\n",
      "[ 0.01  0.01  0.01  0.01  0.01  0.99  0.01  0.01  0.01  0.01]\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "\n",
    "for e in range(epochs):\n",
    "    for record in training_data_list:\n",
    "        all_values = record.split(\",\")\n",
    "        inputs = (numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "        targets = numpy.zeros(n_onodes) + 0.01\n",
    "        targets[int(all_values[0])] = 0.99\n",
    "        print(targets)\n",
    "        break\n",
    "        nn.train(inputs, targets)\n",
    "        pass\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-02T20:26:42.374627Z",
     "start_time": "2017-10-02T20:26:41.760643Z"
    }
   },
   "outputs": [],
   "source": [
    "test_data_file = open(\"MNIST_data/mnist_test.csv\", \"r\")\n",
    "test_data_list = test_data_file.readlines()\n",
    "test_data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-02T20:29:20.544399Z",
     "start_time": "2017-10-02T20:29:20.502058Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "7\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "scorecard = []\n",
    "\n",
    "for record in test_data_list:\n",
    "    all_values = record.split(\",\")\n",
    "    correct_label = int(all_values[0])\n",
    "    \n",
    "    inputs = (numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "    \n",
    "    outputs = nn.query(inputs)\n",
    "    \n",
    "    label = numpy.argmax(outputs)\n",
    "    \n",
    "    scorecard.append(1 if label == correct_label else 0)\n",
    "    print(label)\n",
    "    print(correct_label)\n",
    "    print(label == correct_label)\n",
    "    break\n",
    "    \n",
    "    pass\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-02T20:26:42.479677Z",
     "start_time": "2017-10-02T20:26:42.413205Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performace = 1.0\n"
     ]
    }
   ],
   "source": [
    "scorecard_np = numpy.asarray(scorecard)\n",
    "print(\"Performace = {}\".format(scorecard_np.sum() / scorecard_np.size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-02T20:28:27.680929Z",
     "start_time": "2017-10-02T20:26:42.482855Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 37s, sys: 2.06 s, total: 1min 39s\n",
      "Wall time: 1min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import gzip\n",
    "\n",
    "def convert(imgf, labelf, outf, n):\n",
    "    f = gzip.open(imgf, \"rb\")\n",
    "    o = open(outf, \"w\")\n",
    "    l = gzip.open(labelf, \"rb\")\n",
    "\n",
    "    f.read(16)\n",
    "    l.read(8)\n",
    "    images = []\n",
    "\n",
    "    for i in range(n):\n",
    "        image = [ord(l.read(1))]\n",
    "        for j in range(28*28):\n",
    "            image.append(ord(f.read(1)))\n",
    "        images.append(image)\n",
    "\n",
    "    for image in images:\n",
    "        o.write(\",\".join(str(pix) for pix in image)+\"\\n\")\n",
    "    f.close()\n",
    "    o.close()\n",
    "    l.close()\n",
    "\n",
    "    \n",
    "# Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
    "# Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
    "# Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
    "# Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
    "convert(\"MNIST_data/train-images-idx3-ubyte.gz\", \"MNIST_data/train-labels-idx1-ubyte.gz\",\n",
    "        \"MNIST_data/mnist_train.csv\", 60000)\n",
    "convert(\"MNIST_data/t10k-images-idx3-ubyte.gz\", \"MNIST_data/t10k-labels-idx1-ubyte.gz\",\n",
    "        \"MNIST_data/mnist_test.csv\", 10000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
